{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will demonstrate how to fit a Gaussian Mixture Model to data.\n",
    "I will show how different variations of the model compare to each other\n",
    "- [ ] Initializing randomly vs. with k-means algorithm: accuracy and time to convergence\n",
    "- [ ] Fitting constrained vs. unconstrained Gaussian component distributions: spherical, elliptical, or full-covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import numpy as onp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from movmf.mixture_model import GaussianMixtureModel\n",
    "from movmf.util import draw_confidence_ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "categorical_cmap = ListedColormap(sns.color_palette('husl',9).as_hex())\n",
    "categorical_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observations(seed, n_mixtures, n_dims, n_samples=100, scales=[]):\n",
    "    \"\"\"Generate data-generating GMM and draw samples.\n",
    "    \n",
    "    Differs from gmm.initialize_random bc it provides control over scales.\n",
    "    \"\"\"\n",
    "    \n",
    "    seed_cat, seed_mean, seed_cov, seed_sample = jr.split(seed, 4)\n",
    "    mixing_probs = jr.dirichlet(seed_cat, jnp.ones(n_mixtures))\n",
    "    component_means = jr.normal(seed_mean, (n_mixtures, n_dims))\n",
    "\n",
    "    if len(scales) == 0:\n",
    "        scales = jr.uniform(seed_cov, (n_mixtures,), minval=1.e-3, maxval=3.)\n",
    "    component_covs = jnp.tile(jnp.eye(n_dims), (n_mixtures, 1, 1))\n",
    "    component_covs *= scales[:, None, None]\n",
    "    \n",
    "    true_gmm = GaussianMixtureModel(mixing_probs, component_means, component_covs)\n",
    "    assgns, samples = true_gmm.sample(seed_sample, (n_samples,))\n",
    "    return true_gmm, assgns, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_by_assgn(assgns, *arrs):\n",
    "    \"\"\"Split data into a list of sets by assignment.\n",
    "\n",
    "    NB: Does not catch that case when some mixtures may have 0 assignments.\n",
    "    \n",
    "    Params\n",
    "        assgns[n]: unorder list of M mixture assignments\n",
    "        arrs[n,...]: list of data arrays to be sorted\n",
    "        \n",
    "    Return\n",
    "        *sorted_arrs: input arrays are split into lengths of length (M)\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort indices in ascending order\n",
    "    idx_sort = onp.argsort(onp.asarray(assgns))\n",
    "    sorted_assgns = assgns[idx_sort]\n",
    "    sorted_arrs = [arr[idx_sort,...] for arr in arrs]\n",
    "\n",
    "    # Split arrays by mixture\n",
    "    _, idx_split = onp.unique(sorted_assgns, return_index=True)\n",
    "    split_arrs = [onp.split(arr, idx_split[1:]) for arr in sorted_arrs]\n",
    "\n",
    "    return split_arrs[0] if len(split_arrs)==1 else tuple(split_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from a Gaussian mixture model\n",
    "seed = jr.PRNGKey(340212)\n",
    "seed, seed_scale, seed_init = jr.split(seed, 3)\n",
    "\n",
    "true_n_mixtures = 5\n",
    "component_dim = 2\n",
    "scales = jr.uniform(seed_scale, (true_n_mixtures,), minval=1e-3, maxval=0.5)\n",
    "n_samples = 500\n",
    "true_gmm, true_assgns, samples = generate_observations(\n",
    "    seed_init, true_n_mixtures, component_dim, n_samples, scales\n",
    ")\n",
    "\n",
    "samples_by_mixture = split_data_by_assgn(true_assgns, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot true GMM (3 std of ellipses) and observed samples (scatter) by mixture.\n",
    "# Saturation of true GMM ellipse is indicative of its mixing probability\n",
    "\n",
    "true_means = true_gmm._component_means.value\n",
    "true_covs = true_gmm._component_covariances.value\n",
    "true_probs = onp.asarray(true_gmm._mixing_probs.value)\n",
    "\n",
    "for m, samples_m in enumerate(samples_by_mixture):\n",
    "    c = categorical_cmap(m)\n",
    "    \n",
    "    plt.scatter(samples_m[:,0], samples_m[:,1], s=12, color=c)\n",
    "\n",
    "    # Plot true GMM\n",
    "    alpha = onp.maximum(true_probs[m], 0.05)\n",
    "    draw_confidence_ellipse(true_means[m], true_covs[m], ax=plt.gca(),\n",
    "                                       n_std=[1,2,3], edgecolor='k', facecolor=c, alpha=alpha)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.title(f'Data-generating GMM and samples (n={n_samples})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
